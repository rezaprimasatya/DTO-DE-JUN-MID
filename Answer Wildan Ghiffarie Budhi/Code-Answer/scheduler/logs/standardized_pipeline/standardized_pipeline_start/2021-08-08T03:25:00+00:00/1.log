[2021-08-08 03:30:01,045] {taskinstance.py:896} INFO - Dependencies all met for <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [queued]>
[2021-08-08 03:30:01,064] {taskinstance.py:896} INFO - Dependencies all met for <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [queued]>
[2021-08-08 03:30:01,065] {taskinstance.py:1087} INFO - 
--------------------------------------------------------------------------------
[2021-08-08 03:30:01,066] {taskinstance.py:1088} INFO - Starting attempt 1 of 11
[2021-08-08 03:30:01,066] {taskinstance.py:1089} INFO - 
--------------------------------------------------------------------------------
[2021-08-08 03:30:01,076] {taskinstance.py:1107} INFO - Executing <Task(ExternalTaskSensor): standardized_pipeline_start> on 2021-08-08T03:25:00+00:00
[2021-08-08 03:30:01,081] {standard_task_runner.py:52} INFO - Started process 294 to run task
[2021-08-08 03:30:01,088] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'standardized_pipeline', 'standardized_pipeline_start', '2021-08-08T03:25:00+00:00', '--job-id', '14', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/standardized_pipeline.py', '--cfg-path', '/tmp/tmpvuoslwte', '--error-file', '/tmp/tmpkhar1u_5']
[2021-08-08 03:30:01,089] {standard_task_runner.py:77} INFO - Job 14: Subtask standardized_pipeline_start
[2021-08-08 03:30:01,150] {logging_mixin.py:104} INFO - Running <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [running]> on host daa2bc25bf8a
[2021-08-08 03:30:01,229] {taskinstance.py:1302} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=wildangbudhi@gmail.com
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=standardized_pipeline
AIRFLOW_CTX_TASK_ID=standardized_pipeline_start
AIRFLOW_CTX_EXECUTION_DATE=2021-08-08T03:25:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-08T03:25:00+00:00
[2021-08-08 03:30:01,240] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:30:01,290] {taskinstance.py:1484} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2021-08-08 03:30:01,302] {local_task_job.py:149} INFO - Task exited with return code 0
[2021-08-08 03:30:12,206] {taskinstance.py:896} INFO - Dependencies all met for <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [queued]>
[2021-08-08 03:30:12,227] {taskinstance.py:896} INFO - Dependencies all met for <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [queued]>
[2021-08-08 03:30:12,228] {taskinstance.py:1087} INFO - 
--------------------------------------------------------------------------------
[2021-08-08 03:30:12,229] {taskinstance.py:1088} INFO - Starting attempt 1 of 11
[2021-08-08 03:30:12,230] {taskinstance.py:1089} INFO - 
--------------------------------------------------------------------------------
[2021-08-08 03:30:12,241] {taskinstance.py:1107} INFO - Executing <Task(ExternalTaskSensor): standardized_pipeline_start> on 2021-08-08T03:25:00+00:00
[2021-08-08 03:30:12,246] {standard_task_runner.py:52} INFO - Started process 313 to run task
[2021-08-08 03:30:12,251] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'standardized_pipeline', 'standardized_pipeline_start', '2021-08-08T03:25:00+00:00', '--job-id', '17', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/standardized_pipeline.py', '--cfg-path', '/tmp/tmpwaqz9_60', '--error-file', '/tmp/tmplq2n4xud']
[2021-08-08 03:30:12,253] {standard_task_runner.py:77} INFO - Job 17: Subtask standardized_pipeline_start
[2021-08-08 03:30:12,311] {logging_mixin.py:104} INFO - Running <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [running]> on host daa2bc25bf8a
[2021-08-08 03:30:12,375] {taskinstance.py:1302} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=wildangbudhi@gmail.com
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=standardized_pipeline
AIRFLOW_CTX_TASK_ID=standardized_pipeline_start
AIRFLOW_CTX_EXECUTION_DATE=2021-08-08T03:25:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-08T03:25:00+00:00
[2021-08-08 03:30:12,388] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:30:12,432] {taskinstance.py:1484} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2021-08-08 03:30:12,470] {local_task_job.py:149} INFO - Task exited with return code 0
[2021-08-08 03:30:23,631] {taskinstance.py:896} INFO - Dependencies all met for <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [queued]>
[2021-08-08 03:30:23,652] {taskinstance.py:896} INFO - Dependencies all met for <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [queued]>
[2021-08-08 03:30:23,653] {taskinstance.py:1087} INFO - 
--------------------------------------------------------------------------------
[2021-08-08 03:30:23,654] {taskinstance.py:1088} INFO - Starting attempt 1 of 11
[2021-08-08 03:30:23,655] {taskinstance.py:1089} INFO - 
--------------------------------------------------------------------------------
[2021-08-08 03:30:23,666] {taskinstance.py:1107} INFO - Executing <Task(ExternalTaskSensor): standardized_pipeline_start> on 2021-08-08T03:25:00+00:00
[2021-08-08 03:30:23,678] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'standardized_pipeline', 'standardized_pipeline_start', '2021-08-08T03:25:00+00:00', '--job-id', '19', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/standardized_pipeline.py', '--cfg-path', '/tmp/tmp78g_0vme', '--error-file', '/tmp/tmpsk1l9uqg']
[2021-08-08 03:30:23,672] {standard_task_runner.py:52} INFO - Started process 327 to run task
[2021-08-08 03:30:23,680] {standard_task_runner.py:77} INFO - Job 19: Subtask standardized_pipeline_start
[2021-08-08 03:30:23,746] {logging_mixin.py:104} INFO - Running <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [running]> on host daa2bc25bf8a
[2021-08-08 03:30:23,809] {taskinstance.py:1302} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=wildangbudhi@gmail.com
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=standardized_pipeline
AIRFLOW_CTX_TASK_ID=standardized_pipeline_start
AIRFLOW_CTX_EXECUTION_DATE=2021-08-08T03:25:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-08T03:25:00+00:00
[2021-08-08 03:30:23,821] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:30:23,857] {taskinstance.py:1484} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2021-08-08 03:30:23,897] {local_task_job.py:149} INFO - Task exited with return code 0
[2021-08-08 03:30:34,939] {taskinstance.py:896} INFO - Dependencies all met for <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [queued]>
[2021-08-08 03:30:34,957] {taskinstance.py:896} INFO - Dependencies all met for <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [queued]>
[2021-08-08 03:30:34,958] {taskinstance.py:1087} INFO - 
--------------------------------------------------------------------------------
[2021-08-08 03:30:34,959] {taskinstance.py:1088} INFO - Starting attempt 1 of 11
[2021-08-08 03:30:34,959] {taskinstance.py:1089} INFO - 
--------------------------------------------------------------------------------
[2021-08-08 03:30:34,969] {taskinstance.py:1107} INFO - Executing <Task(ExternalTaskSensor): standardized_pipeline_start> on 2021-08-08T03:25:00+00:00
[2021-08-08 03:30:34,975] {standard_task_runner.py:52} INFO - Started process 348 to run task
[2021-08-08 03:30:34,981] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'standardized_pipeline', 'standardized_pipeline_start', '2021-08-08T03:25:00+00:00', '--job-id', '21', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/standardized_pipeline.py', '--cfg-path', '/tmp/tmpi7jddvsq', '--error-file', '/tmp/tmp7jod3jas']
[2021-08-08 03:30:34,983] {standard_task_runner.py:77} INFO - Job 21: Subtask standardized_pipeline_start
[2021-08-08 03:30:35,042] {logging_mixin.py:104} INFO - Running <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [running]> on host daa2bc25bf8a
[2021-08-08 03:30:35,103] {taskinstance.py:1302} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=wildangbudhi@gmail.com
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=standardized_pipeline
AIRFLOW_CTX_TASK_ID=standardized_pipeline_start
AIRFLOW_CTX_EXECUTION_DATE=2021-08-08T03:25:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-08T03:25:00+00:00
[2021-08-08 03:30:35,115] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:30:35,150] {taskinstance.py:1484} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2021-08-08 03:30:35,197] {local_task_job.py:149} INFO - Task exited with return code 0
[2021-08-08 03:30:45,539] {taskinstance.py:896} INFO - Dependencies all met for <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [queued]>
[2021-08-08 03:30:45,561] {taskinstance.py:896} INFO - Dependencies all met for <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [queued]>
[2021-08-08 03:30:45,562] {taskinstance.py:1087} INFO - 
--------------------------------------------------------------------------------
[2021-08-08 03:30:45,563] {taskinstance.py:1088} INFO - Starting attempt 1 of 11
[2021-08-08 03:30:45,564] {taskinstance.py:1089} INFO - 
--------------------------------------------------------------------------------
[2021-08-08 03:30:45,574] {taskinstance.py:1107} INFO - Executing <Task(ExternalTaskSensor): standardized_pipeline_start> on 2021-08-08T03:25:00+00:00
[2021-08-08 03:30:45,586] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'standardized_pipeline', 'standardized_pipeline_start', '2021-08-08T03:25:00+00:00', '--job-id', '23', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/standardized_pipeline.py', '--cfg-path', '/tmp/tmp5wicu1on', '--error-file', '/tmp/tmplfb6laa1']
[2021-08-08 03:30:45,580] {standard_task_runner.py:52} INFO - Started process 369 to run task
[2021-08-08 03:30:45,588] {standard_task_runner.py:77} INFO - Job 23: Subtask standardized_pipeline_start
[2021-08-08 03:30:45,648] {logging_mixin.py:104} INFO - Running <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [running]> on host daa2bc25bf8a
[2021-08-08 03:30:45,709] {taskinstance.py:1302} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=wildangbudhi@gmail.com
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=standardized_pipeline
AIRFLOW_CTX_TASK_ID=standardized_pipeline_start
AIRFLOW_CTX_EXECUTION_DATE=2021-08-08T03:25:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-08T03:25:00+00:00
[2021-08-08 03:30:45,721] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:30:45,756] {taskinstance.py:1484} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2021-08-08 03:30:45,804] {local_task_job.py:149} INFO - Task exited with return code 0
[2021-08-08 03:30:56,828] {taskinstance.py:896} INFO - Dependencies all met for <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [queued]>
[2021-08-08 03:30:56,846] {taskinstance.py:896} INFO - Dependencies all met for <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [queued]>
[2021-08-08 03:30:56,847] {taskinstance.py:1087} INFO - 
--------------------------------------------------------------------------------
[2021-08-08 03:30:56,848] {taskinstance.py:1088} INFO - Starting attempt 1 of 11
[2021-08-08 03:30:56,849] {taskinstance.py:1089} INFO - 
--------------------------------------------------------------------------------
[2021-08-08 03:30:56,858] {taskinstance.py:1107} INFO - Executing <Task(ExternalTaskSensor): standardized_pipeline_start> on 2021-08-08T03:25:00+00:00
[2021-08-08 03:30:56,868] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'standardized_pipeline', 'standardized_pipeline_start', '2021-08-08T03:25:00+00:00', '--job-id', '25', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/standardized_pipeline.py', '--cfg-path', '/tmp/tmpf3gx3jft', '--error-file', '/tmp/tmpbat8gitl']
[2021-08-08 03:30:56,863] {standard_task_runner.py:52} INFO - Started process 391 to run task
[2021-08-08 03:30:56,870] {standard_task_runner.py:77} INFO - Job 25: Subtask standardized_pipeline_start
[2021-08-08 03:30:56,926] {logging_mixin.py:104} INFO - Running <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [running]> on host daa2bc25bf8a
[2021-08-08 03:30:56,964] {taskinstance.py:1302} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=wildangbudhi@gmail.com
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=standardized_pipeline
AIRFLOW_CTX_TASK_ID=standardized_pipeline_start
AIRFLOW_CTX_EXECUTION_DATE=2021-08-08T03:25:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-08T03:25:00+00:00
[2021-08-08 03:30:56,975] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:30:57,008] {taskinstance.py:1484} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2021-08-08 03:30:57,022] {local_task_job.py:149} INFO - Task exited with return code 0
[2021-08-08 03:31:08,144] {taskinstance.py:896} INFO - Dependencies all met for <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [queued]>
[2021-08-08 03:31:08,164] {taskinstance.py:896} INFO - Dependencies all met for <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [queued]>
[2021-08-08 03:31:08,165] {taskinstance.py:1087} INFO - 
--------------------------------------------------------------------------------
[2021-08-08 03:31:08,166] {taskinstance.py:1088} INFO - Starting attempt 1 of 11
[2021-08-08 03:31:08,167] {taskinstance.py:1089} INFO - 
--------------------------------------------------------------------------------
[2021-08-08 03:31:08,177] {taskinstance.py:1107} INFO - Executing <Task(ExternalTaskSensor): standardized_pipeline_start> on 2021-08-08T03:25:00+00:00
[2021-08-08 03:31:08,189] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'standardized_pipeline', 'standardized_pipeline_start', '2021-08-08T03:25:00+00:00', '--job-id', '27', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/standardized_pipeline.py', '--cfg-path', '/tmp/tmp44gy0nhs', '--error-file', '/tmp/tmpu_hi7sf9']
[2021-08-08 03:31:08,184] {standard_task_runner.py:52} INFO - Started process 412 to run task
[2021-08-08 03:31:08,191] {standard_task_runner.py:77} INFO - Job 27: Subtask standardized_pipeline_start
[2021-08-08 03:31:08,244] {logging_mixin.py:104} INFO - Running <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [running]> on host daa2bc25bf8a
[2021-08-08 03:31:08,297] {taskinstance.py:1302} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=wildangbudhi@gmail.com
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=standardized_pipeline
AIRFLOW_CTX_TASK_ID=standardized_pipeline_start
AIRFLOW_CTX_EXECUTION_DATE=2021-08-08T03:25:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-08T03:25:00+00:00
[2021-08-08 03:31:08,307] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:31:08,337] {taskinstance.py:1484} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2021-08-08 03:31:08,367] {local_task_job.py:149} INFO - Task exited with return code 0
[2021-08-08 03:31:19,012] {taskinstance.py:896} INFO - Dependencies all met for <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [queued]>
[2021-08-08 03:31:19,029] {taskinstance.py:896} INFO - Dependencies all met for <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [queued]>
[2021-08-08 03:31:19,030] {taskinstance.py:1087} INFO - 
--------------------------------------------------------------------------------
[2021-08-08 03:31:19,030] {taskinstance.py:1088} INFO - Starting attempt 1 of 11
[2021-08-08 03:31:19,031] {taskinstance.py:1089} INFO - 
--------------------------------------------------------------------------------
[2021-08-08 03:31:19,039] {taskinstance.py:1107} INFO - Executing <Task(ExternalTaskSensor): standardized_pipeline_start> on 2021-08-08T03:25:00+00:00
[2021-08-08 03:31:19,048] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'standardized_pipeline', 'standardized_pipeline_start', '2021-08-08T03:25:00+00:00', '--job-id', '29', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/standardized_pipeline.py', '--cfg-path', '/tmp/tmpctlyjftj', '--error-file', '/tmp/tmp1w61tjz1']
[2021-08-08 03:31:19,044] {standard_task_runner.py:52} INFO - Started process 433 to run task
[2021-08-08 03:31:19,050] {standard_task_runner.py:77} INFO - Job 29: Subtask standardized_pipeline_start
[2021-08-08 03:31:19,100] {logging_mixin.py:104} INFO - Running <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [running]> on host daa2bc25bf8a
[2021-08-08 03:31:19,152] {taskinstance.py:1302} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=wildangbudhi@gmail.com
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=standardized_pipeline
AIRFLOW_CTX_TASK_ID=standardized_pipeline_start
AIRFLOW_CTX_EXECUTION_DATE=2021-08-08T03:25:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-08T03:25:00+00:00
[2021-08-08 03:31:19,162] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:31:19,191] {taskinstance.py:1484} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2021-08-08 03:31:19,227] {local_task_job.py:149} INFO - Task exited with return code 0
[2021-08-08 03:31:29,527] {taskinstance.py:896} INFO - Dependencies all met for <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [queued]>
[2021-08-08 03:31:29,546] {taskinstance.py:896} INFO - Dependencies all met for <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [queued]>
[2021-08-08 03:31:29,547] {taskinstance.py:1087} INFO - 
--------------------------------------------------------------------------------
[2021-08-08 03:31:29,548] {taskinstance.py:1088} INFO - Starting attempt 1 of 11
[2021-08-08 03:31:29,549] {taskinstance.py:1089} INFO - 
--------------------------------------------------------------------------------
[2021-08-08 03:31:29,558] {taskinstance.py:1107} INFO - Executing <Task(ExternalTaskSensor): standardized_pipeline_start> on 2021-08-08T03:25:00+00:00
[2021-08-08 03:31:29,568] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'standardized_pipeline', 'standardized_pipeline_start', '2021-08-08T03:25:00+00:00', '--job-id', '31', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/standardized_pipeline.py', '--cfg-path', '/tmp/tmp2t3u7zzh', '--error-file', '/tmp/tmpngpeil6x']
[2021-08-08 03:31:29,563] {standard_task_runner.py:52} INFO - Started process 447 to run task
[2021-08-08 03:31:29,570] {standard_task_runner.py:77} INFO - Job 31: Subtask standardized_pipeline_start
[2021-08-08 03:31:29,633] {logging_mixin.py:104} INFO - Running <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [running]> on host daa2bc25bf8a
[2021-08-08 03:31:29,699] {taskinstance.py:1302} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=wildangbudhi@gmail.com
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=standardized_pipeline
AIRFLOW_CTX_TASK_ID=standardized_pipeline_start
AIRFLOW_CTX_EXECUTION_DATE=2021-08-08T03:25:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-08T03:25:00+00:00
[2021-08-08 03:31:29,710] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:31:29,753] {taskinstance.py:1484} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2021-08-08 03:31:29,785] {local_task_job.py:149} INFO - Task exited with return code 0
[2021-08-08 03:33:50,068] {taskinstance.py:896} INFO - Dependencies all met for <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [queued]>
[2021-08-08 03:33:50,096] {taskinstance.py:896} INFO - Dependencies all met for <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [queued]>
[2021-08-08 03:33:50,097] {taskinstance.py:1087} INFO - 
--------------------------------------------------------------------------------
[2021-08-08 03:33:50,098] {taskinstance.py:1088} INFO - Starting attempt 1 of 11
[2021-08-08 03:33:50,099] {taskinstance.py:1089} INFO - 
--------------------------------------------------------------------------------
[2021-08-08 03:33:50,115] {taskinstance.py:1107} INFO - Executing <Task(ExternalTaskSensor): standardized_pipeline_start> on 2021-08-08T03:25:00+00:00
[2021-08-08 03:33:50,123] {standard_task_runner.py:52} INFO - Started process 138 to run task
[2021-08-08 03:33:50,131] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'standardized_pipeline', 'standardized_pipeline_start', '2021-08-08T03:25:00+00:00', '--job-id', '2', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/standardized_pipeline.py', '--cfg-path', '/tmp/tmpy6kp_fug', '--error-file', '/tmp/tmpexge_f5m']
[2021-08-08 03:33:50,134] {standard_task_runner.py:77} INFO - Job 2: Subtask standardized_pipeline_start
[2021-08-08 03:33:50,217] {logging_mixin.py:104} INFO - Running <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T03:25:00+00:00 [running]> on host 048dd2156ea9
[2021-08-08 03:33:50,314] {taskinstance.py:1302} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=wildangbudhi@gmail.com
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=standardized_pipeline
AIRFLOW_CTX_TASK_ID=standardized_pipeline_start
AIRFLOW_CTX_EXECUTION_DATE=2021-08-08T03:25:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-08T03:25:00+00:00
[2021-08-08 03:33:50,316] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:34:00,314] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:34:10,342] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:34:20,368] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:34:30,375] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:34:40,402] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:34:50,432] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:35:00,435] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:35:10,463] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:35:20,482] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:35:30,487] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:35:40,513] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:35:50,540] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:36:00,543] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:36:10,567] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:36:20,596] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:36:30,597] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:36:40,614] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:36:50,627] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:37:00,630] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:37:10,645] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:37:20,663] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:37:30,665] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:37:40,682] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:37:50,707] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:38:00,710] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
[2021-08-08 03:38:10,729] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end_task on 2021-08-08T03:25:00+00:00 ... 
