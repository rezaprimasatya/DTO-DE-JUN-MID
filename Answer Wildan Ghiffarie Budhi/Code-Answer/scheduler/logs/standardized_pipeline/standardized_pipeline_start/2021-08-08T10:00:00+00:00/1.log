[2021-08-08 11:00:00,967] {taskinstance.py:896} INFO - Dependencies all met for <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T10:00:00+00:00 [queued]>
[2021-08-08 11:00:00,979] {taskinstance.py:896} INFO - Dependencies all met for <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T10:00:00+00:00 [queued]>
[2021-08-08 11:00:00,979] {taskinstance.py:1087} INFO - 
--------------------------------------------------------------------------------
[2021-08-08 11:00:00,980] {taskinstance.py:1088} INFO - Starting attempt 1 of 11
[2021-08-08 11:00:00,981] {taskinstance.py:1089} INFO - 
--------------------------------------------------------------------------------
[2021-08-08 11:00:00,992] {taskinstance.py:1107} INFO - Executing <Task(ExternalTaskSensor): standardized_pipeline_start> on 2021-08-08T10:00:00+00:00
[2021-08-08 11:00:00,997] {standard_task_runner.py:52} INFO - Started process 10908 to run task
[2021-08-08 11:00:01,001] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'standardized_pipeline', 'standardized_pipeline_start', '2021-08-08T10:00:00+00:00', '--job-id', '95', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/standardized_pipeline.py', '--cfg-path', '/tmp/tmpth4toyes', '--error-file', '/tmp/tmp5e2ovpn1']
[2021-08-08 11:00:01,003] {standard_task_runner.py:77} INFO - Job 95: Subtask standardized_pipeline_start
[2021-08-08 11:00:01,050] {logging_mixin.py:104} INFO - Running <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T10:00:00+00:00 [running]> on host 99eefc5c6cd8
[2021-08-08 11:00:01,102] {taskinstance.py:1302} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=standardized_pipeline
AIRFLOW_CTX_TASK_ID=standardized_pipeline_start
AIRFLOW_CTX_EXECUTION_DATE=2021-08-08T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-08T10:00:00+00:00
[2021-08-08 11:00:01,104] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end on 2021-08-08T10:00:00+00:00 ... 
[2021-08-08 11:01:01,103] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end on 2021-08-08T10:00:00+00:00 ... 
[2021-08-08 11:01:01,116] {base.py:248} INFO - Success criteria met. Exiting.
[2021-08-08 11:01:01,126] {taskinstance.py:1211} INFO - Marking task as SUCCESS. dag_id=standardized_pipeline, task_id=standardized_pipeline_start, execution_date=20210808T100000, start_date=20210808T110000, end_date=20210808T110101
[2021-08-08 11:01:01,171] {taskinstance.py:1265} INFO - 8 downstream tasks scheduled from follow-on schedule check
[2021-08-08 11:01:01,208] {local_task_job.py:149} INFO - Task exited with return code 0
[2021-08-08 11:03:32,641] {taskinstance.py:896} INFO - Dependencies all met for <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T10:00:00+00:00 [queued]>
[2021-08-08 11:03:32,657] {taskinstance.py:896} INFO - Dependencies all met for <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T10:00:00+00:00 [queued]>
[2021-08-08 11:03:32,658] {taskinstance.py:1087} INFO - 
--------------------------------------------------------------------------------
[2021-08-08 11:03:32,659] {taskinstance.py:1088} INFO - Starting attempt 1 of 11
[2021-08-08 11:03:32,659] {taskinstance.py:1089} INFO - 
--------------------------------------------------------------------------------
[2021-08-08 11:03:32,667] {taskinstance.py:1107} INFO - Executing <Task(ExternalTaskSensor): standardized_pipeline_start> on 2021-08-08T10:00:00+00:00
[2021-08-08 11:03:32,671] {standard_task_runner.py:52} INFO - Started process 156 to run task
[2021-08-08 11:03:32,676] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'standardized_pipeline', 'standardized_pipeline_start', '2021-08-08T10:00:00+00:00', '--job-id', '2', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/standardized_pipeline.py', '--cfg-path', '/tmp/tmpvw7wpym3', '--error-file', '/tmp/tmpxmdm85pf']
[2021-08-08 11:03:32,678] {standard_task_runner.py:77} INFO - Job 2: Subtask standardized_pipeline_start
[2021-08-08 11:03:32,724] {logging_mixin.py:104} INFO - Running <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T10:00:00+00:00 [running]> on host ce886ce1d63a
[2021-08-08 11:03:32,779] {taskinstance.py:1302} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=standardized_pipeline
AIRFLOW_CTX_TASK_ID=standardized_pipeline_start
AIRFLOW_CTX_EXECUTION_DATE=2021-08-08T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-08T10:00:00+00:00
[2021-08-08 11:03:32,780] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end on 2021-08-08T10:00:00+00:00 ... 
[2021-08-08 11:04:32,781] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end on 2021-08-08T10:00:00+00:00 ... 
[2021-08-08 11:04:32,794] {base.py:248} INFO - Success criteria met. Exiting.
[2021-08-08 11:04:32,803] {taskinstance.py:1211} INFO - Marking task as SUCCESS. dag_id=standardized_pipeline, task_id=standardized_pipeline_start, execution_date=20210808T100000, start_date=20210808T110332, end_date=20210808T110432
[2021-08-08 11:04:32,842] {taskinstance.py:1265} INFO - 8 downstream tasks scheduled from follow-on schedule check
[2021-08-08 11:04:32,861] {local_task_job.py:149} INFO - Task exited with return code 0
[2021-08-08 11:54:51,836] {taskinstance.py:896} INFO - Dependencies all met for <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T10:00:00+00:00 [queued]>
[2021-08-08 11:54:51,847] {taskinstance.py:896} INFO - Dependencies all met for <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T10:00:00+00:00 [queued]>
[2021-08-08 11:54:51,848] {taskinstance.py:1087} INFO - 
--------------------------------------------------------------------------------
[2021-08-08 11:54:51,849] {taskinstance.py:1088} INFO - Starting attempt 1 of 11
[2021-08-08 11:54:51,849] {taskinstance.py:1089} INFO - 
--------------------------------------------------------------------------------
[2021-08-08 11:54:51,862] {taskinstance.py:1107} INFO - Executing <Task(ExternalTaskSensor): standardized_pipeline_start> on 2021-08-08T10:00:00+00:00
[2021-08-08 11:54:51,866] {standard_task_runner.py:52} INFO - Started process 208 to run task
[2021-08-08 11:54:51,870] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'standardized_pipeline', 'standardized_pipeline_start', '2021-08-08T10:00:00+00:00', '--job-id', '2', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/standardized_pipeline.py', '--cfg-path', '/tmp/tmpkryblgs3', '--error-file', '/tmp/tmpkxzzuv8r']
[2021-08-08 11:54:51,872] {standard_task_runner.py:77} INFO - Job 2: Subtask standardized_pipeline_start
[2021-08-08 11:54:51,916] {logging_mixin.py:104} INFO - Running <TaskInstance: standardized_pipeline.standardized_pipeline_start 2021-08-08T10:00:00+00:00 [running]> on host 7f57f947ae95
[2021-08-08 11:54:51,965] {taskinstance.py:1302} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=standardized_pipeline
AIRFLOW_CTX_TASK_ID=standardized_pipeline_start
AIRFLOW_CTX_EXECUTION_DATE=2021-08-08T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-08T10:00:00+00:00
[2021-08-08 11:54:51,966] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end on 2021-08-08T10:00:00+00:00 ... 
[2021-08-08 11:55:51,922] {external_task.py:152} INFO - Poking for to_datalake_pipeline.to_datalake_pipeline_end on 2021-08-08T10:00:00+00:00 ... 
[2021-08-08 11:55:51,932] {base.py:248} INFO - Success criteria met. Exiting.
[2021-08-08 11:55:51,942] {taskinstance.py:1211} INFO - Marking task as SUCCESS. dag_id=standardized_pipeline, task_id=standardized_pipeline_start, execution_date=20210808T100000, start_date=20210808T115451, end_date=20210808T115551
[2021-08-08 11:55:51,982] {taskinstance.py:1265} INFO - 8 downstream tasks scheduled from follow-on schedule check
[2021-08-08 11:55:52,009] {local_task_job.py:149} INFO - Task exited with return code 0
